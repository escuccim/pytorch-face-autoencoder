{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvRcQIxISJ30"
   },
   "source": [
    "# **Homework 9: Variational Autoencoders**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJQ_deIUSca8"
   },
   "source": [
    "## **About**\n",
    "\n",
    "### **Due**\n",
    "\n",
    "Monday 4/29/19, 11:59 PM CST\n",
    "\n",
    "### **Goal**\n",
    "\n",
    "This homework focuses on creating variational autoencoders applied to the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_TOu0F9Sze-"
   },
   "source": [
    "## Dev Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1191
    },
    "colab_type": "code",
    "id": "wGhQFX4H4SK8",
    "outputId": "981254ec-6319-4a01-c2fa-8071b0d588e7"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle-cli\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YB1d0Rm6SWiB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# import wget\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cIPFIJ57Ib3F"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "OfnxTa-rYxhS",
    "outputId": "ee93913d-38bd-4823-8bce-04af3944b1d6"
   },
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_USERNAME']=\"skooch\"\n",
    "os.environ['KAGGLE_KEY']=\"c5356997e70d50a333ef244bd276e51d\"\n",
    "\n",
    "# upload checkpoint to GCS\n",
    "project_id = 'mammography-198911'\n",
    "bucket_name = 'pneumonia'\n",
    "\n",
    "!gcloud config set project {project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "6cSr1AoQInIa",
    "outputId": "01e3e568-c1ab-4a96-830d-2606e418b4b5"
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://{bucket_name}/model_20.pt ./model_2.pt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "Zphgm17rYd1-",
    "outputId": "c68d8a31-6819-43d4-f284-408b3d78e023"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"celeba-dataset.zip\"):\n",
    "#   !kaggle datasets download -d jessicali9530/celeba-dataset\n",
    "  !gsutil cp gs://{bucket_name}/celeba-dataset.zip ./celeba-dataset.zip\n",
    "  zip_ref = zipfile.ZipFile('celeba-dataset.zip', 'r')\n",
    "  zip_ref.extractall('data')\n",
    "  zip_ref.close()\n",
    "\n",
    "  zip_ref = zipfile.ZipFile('data/img_align_celeba.zip', 'r')\n",
    "  zip_ref.extractall('data/images')\n",
    "  zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "8xAiI3XHnyto",
    "outputId": "224fc981-2735-4067-b65b-b0782e6c7603"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Training_Pictures.zip\"):\n",
    "  !wget https://s3.eu-west-3.amazonaws.com/deep.skoo.ch/Training_Pictures.zip\n",
    "  zip_ref = zipfile.ZipFile('Training_Pictures.zip', 'r')\n",
    "  zip_ref.extractall('data/images')\n",
    "  zip_ref.close()\n",
    "  \n",
    "# if not os.path.exists(\"GWB_200x200_JPEG.zip\"):\n",
    "#   !wget https://s3.eu-west-3.amazonaws.com/deep.skoo.ch/GWB_200x200_JPEG.zip\n",
    "#   zip_ref = zipfile.ZipFile('GWB_200x200_JPEG.zip', 'r')\n",
    "#   zip_ref.extractall('data/images')\n",
    "#   zip_ref.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "dWiiNUCtNrJC",
    "outputId": "0779012d-181d-46ce-9a16-b6105f4e81f7"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"wiki_images2.zip\"):\n",
    "  !gsutil cp gs://{bucket_name}/wiki_images2.zip ./wiki_images.zip\n",
    "  zip_ref = zipfile.ZipFile('wiki_images.zip', 'r')\n",
    "  zip_ref.extractall('data/images')\n",
    "  zip_ref.close()\n",
    "  \n",
    "if not os.path.exists(\"imdb_images3.zip\"):\n",
    "  !gsutil cp gs://{bucket_name}/imdb_images3.zip ./imdb_images3.zip\n",
    "  zip_ref = zipfile.ZipFile('imdb_images3.zip', 'r')\n",
    "  zip_ref.extractall('data/images')\n",
    "  zip_ref.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VFBEkk5aT0Xy"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "data_path = \"data/images\"\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.RandomHorizontalFlip(p=0.5), \n",
    "      torchvision.transforms.RandomApply([\n",
    "        torchvision.transforms.RandomAffine(degrees=5, translate=(0.05,0.05), scale=(0.9,1.1), shear=2, resample=False, fillcolor=0),        \n",
    "      ], 0.4),\n",
    "      torchvision.transforms.RandomResizedCrop((192,160), scale=(0.90, 1.1)),\n",
    "      torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "HoiSqJqxbwYq",
    "outputId": "c7cc6654-64b9-41da-ca56-65a4e6dd53ae"
   },
   "outputs": [],
   "source": [
    "for (images, _) in train_loader:\n",
    "  plt.imshow(images[0].permute(1,2,0))\n",
    "  plt.show()\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "id": "grDrowsxNvjz",
    "outputId": "2a0858cb-456c-40fb-8b2b-5ef4591f1171"
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EVLKgjhj4Nsm"
   },
   "outputs": [],
   "source": [
    "def output_size(i, k=3, p=2, s=1, d=1):\n",
    "    o = (i + 2*p - k - (k-1)*(d-1))/s + 1\n",
    "    return o\n",
    "  \n",
    "output_size(i=64, k=3, p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWnRRtR4bTJQ"
   },
   "source": [
    "### Bigger Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FJV6t-RxAAoh"
   },
   "outputs": [],
   "source": [
    "epoch_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fbiSNI4Fy6H2"
   },
   "outputs": [],
   "source": [
    "def vae_loss(x, x_hat, mu=None, logvar=None):\n",
    "    MSE = nn.functional.mse_loss(x, x_hat)\n",
    "    \n",
    "    if mu is not None and logvar is not None:\n",
    "      KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "      KLD /= BATCH_SIZE * 784\n",
    "      MSE = MSE + KLD\n",
    "      \n",
    "    return MSE\n",
    "  \n",
    "def train(model, train_loader, optimizer, print_metrics=100, num_epochs=10, display_images=5, scheduler=None, save_path=\"model_2.pt\"):\n",
    "    model.train()\n",
    "    try:\n",
    "      for epoch in range(num_epochs):\n",
    "          upload_path = save_path.split(\".\")[0] + str(len(epoch_list) % 2) + \".pt\" \n",
    "          \n",
    "          tr_loss = 0.0\n",
    "          batch_losses = []\n",
    "          for i, (inputs, _) in enumerate(train_loader):\n",
    "              if use_cuda and torch.cuda.is_available():\n",
    "                  inputs = inputs.cuda()\n",
    "\n",
    "              optimizer.zero_grad()\n",
    "\n",
    "              recon, code, logvar = model(inputs)\n",
    "              if model.variational:\n",
    "                  loss = vae_loss(inputs, recon, code, logvar=logvar)\n",
    "              else:  \n",
    "                  loss = vae_loss(inputs, recon, code, logvar=None)\n",
    "\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "\n",
    "              tr_loss += loss.item()\n",
    "              batch_losses.append(loss.item())\n",
    "              if print_metrics and i % print_metrics == 0:\n",
    "                  print(\"Batch:\", i, \"loss:\", np.mean(batch_losses))\n",
    "                  batch_losses = []\n",
    "\n",
    "              if i % 1000 == 0 and i > 0:\n",
    "                print(\"\\tEpoch\", len(epoch_list), \"batch\", i, \"loss:\", loss.item())\n",
    "\n",
    "              if i % 4000 == 0 and i > 0:\n",
    "                fig, ax = plt.subplots(1, 2, figsize=(6,6))\n",
    "                ax[0].imshow(inputs[0].cpu().permute(1, 2, 0) )\n",
    "                ax[1].imshow(recon[0].cpu().detach().permute(1, 2, 0) )\n",
    "                plt.show()\n",
    "\n",
    "          print(\"Epoch:\", len(epoch_list), \"Loss:\", tr_loss)\n",
    "          \n",
    "          epoch_list.append(epoch)\n",
    "          \n",
    "          if scheduler is not None and epoch % 5 == 0 and epoch > 1:\n",
    "              scheduler.step()\n",
    "\n",
    "          if epoch % display_images == 0:\n",
    "              # plot a few random images\n",
    "              try:\n",
    "                  fig, ax = plt.subplots(1, 2, figsize=(6,6))\n",
    "                  ax[0].imshow(inputs[0].cpu().permute(1, 2, 0) )\n",
    "                  ax[1].imshow(recon[0].cpu().detach().permute(1, 2, 0) )\n",
    "                  plt.show()\n",
    "              except Exception as e:\n",
    "                  print(e)\n",
    "\n",
    "              torch.save(model.state_dict(), save_path)\n",
    "#               !gsutil cp ./model.pt gs://{bucket_name}/\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "      print(\"Interrupting... Saving model...\")\n",
    "      torch.save(model.state_dict(), save_path)\n",
    "      !gsutil cp {save_path} gs://{bucket_name}/{upload_path}\n",
    "      return \n",
    "    \n",
    "    !gsutil cp {save_path} gs://{bucket_name}/{upload_path}\n",
    "    \n",
    "def count_params(model):\n",
    "  model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "  params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "  return params                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LB63-P6PbVOU"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim, variational=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        # block 1\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)        \n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.downsize1 = nn.Conv2d(96, 64, 1)\n",
    "        \n",
    "        # block 2\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.downsize2 = nn.Conv2d(192, 128, 1)\n",
    "        \n",
    "        # block 3\n",
    "        self.conv7 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.downsize3 = nn.Conv2d(384, 256, 1)\n",
    "        \n",
    "        # block 4\n",
    "        self.conv10 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.downsize4 = nn.Conv2d(512, 384, 1)\n",
    "        \n",
    "        # block 5\n",
    "        self.conv12 = nn.Conv2d(384, 384, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(384, 384, 3, padding=1)\n",
    "        self.downsize5 = nn.Conv2d(768, 512, 1)\n",
    "        \n",
    "        self.fc1 = nn.Conv2d(512, latent_dim, (6,5)) # code layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(2,2)\n",
    "        self.variational = variational\n",
    "        \n",
    "    def encode(self, x):\n",
    "        # input 178x178x3 - output 80x80x32\n",
    "        h1 = self.relu(self.conv1(x))\n",
    "        h2 = self.relu(self.conv2(h1))\n",
    "        h3 = self.relu(self.conv3(h2))\n",
    "        ds1 = self.relu(self.downsize1(torch.cat((h1,h2,h3), 1)))\n",
    "        mp1 = self.max_pool(ds1)\n",
    "        \n",
    "        # input 89x89x32 - output 64x40x40\n",
    "        h4 = self.conv4(mp1)\n",
    "        h5 = self.relu(self.conv5(self.relu(h4)))\n",
    "        h6 = self.relu(self.conv6(h5))\n",
    "        ds2 = self.relu(self.downsize2(torch.cat((h4,h5,h6), 1)))\n",
    "        mp2 = self.max_pool(ds2)\n",
    "        \n",
    "        # input 54x44x64 - output 128x20x20\n",
    "        h7 = self.conv7(mp2)\n",
    "        h8 = self.relu(self.conv8(self.relu(h7)))\n",
    "        h9 = self.relu(self.conv9(h8))\n",
    "        ds3 = self.relu(self.downsize3(torch.cat((h7,h8,h9), 1)))\n",
    "        mp3 = self.max_pool(ds3)\n",
    "        \n",
    "        # input 128x22x22 - output 256x10x10\n",
    "        h10 = self.relu(self.conv10(mp3))\n",
    "        h11 = self.relu(self.conv11(h10))\n",
    "        ds4 = self.relu(self.downsize4(torch.cat((h10,h11), 1)))\n",
    "        mp4 = self.max_pool(ds4)\n",
    "        \n",
    "        # input 256x11x11 - output 384x5x5\n",
    "        h12 = self.relu(self.conv12(mp4))\n",
    "        h13 = self.relu(self.conv13(h12))\n",
    "        ds5 = self.relu(self.downsize5(torch.cat((h12,h13), 1)))\n",
    "        mp5 = self.max_pool(ds5)\n",
    "        \n",
    "        # input 4x4x64 - output latent_dimx1\n",
    "        code = self.fc1(mp5)\n",
    "        logvar = None\n",
    "  \n",
    "        return code, logvar\n",
    "  \n",
    "    def forward(self, x):\n",
    "        code, logvar = self.encode(x)\n",
    "        return code, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.ConvTranspose2d(latent_dim, 384, (6,5), stride=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(384, 256, 2, stride=2, output_padding=0)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 224, 2, stride=2, output_padding=0)\n",
    "        self.deconv4 = nn.ConvTranspose2d(224, 192, 2, stride=2, output_padding=0)\n",
    "        self.deconv5 = nn.ConvTranspose2d(192, 156, 2, stride=2, output_padding=0)\n",
    "        self.deconv6 = nn.ConvTranspose2d(156, 128, 2, stride=2, output_padding=0)\n",
    "#         self.deconv7 = nn.ConvTranspose2d(128, 64, 2, stride=1)\n",
    "        self.deconv8 = nn.Conv2d(128, 3, 1, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "  \n",
    "    def decode(self, x):\n",
    "        # input latent_dimx1 - output 2048x1\n",
    "        h0 = self.relu(self.fc1(x))\n",
    "        \n",
    "        # in 5x5 - out 10x10\n",
    "        h1 = self.relu(self.deconv1(h0))\n",
    "        \n",
    "        # in 10x10 - out 20x20\n",
    "        h3 = self.relu(self.deconv3(h1))\n",
    "        h4 = self.relu(self.deconv4(h3))\n",
    "        h5 = self.relu(self.deconv5(h4))\n",
    "        h6 = self.relu(self.deconv6(h5))\n",
    "#         h7 = self.relu(self.deconv7(h6, output_size=(160,160)))\n",
    "        h8 = self.deconv8(h6)\n",
    "      \n",
    "        return self.sigmoid(h8)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decode(x)\n",
    "    \n",
    "# a model that uses the Encoder and Decoder\n",
    "class SingleModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder, variational=False):\n",
    "        super(SingleModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.variational = variational\n",
    "\n",
    "    def sample(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.autograd.Variable(std.data.new(std.size()).normal_())\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def forward(self, X):\n",
    "        mu, logvar = encoder(X)\n",
    "\n",
    "        if self.training and logvar is not None:\n",
    "            z = self.sample(mu, logvar)\n",
    "        else:\n",
    "            z = mu\n",
    "            \n",
    "        recon = self.decoder(z)\n",
    "        \n",
    "        return recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "0JGv_rs2fJkA",
    "outputId": "13000c37-2910-4a6e-a77e-ffd1a0b2feba"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "  ## YOUR CODE HERE ##\n",
    "encoder = Encoder(4096, variational=False)\n",
    "decoder = Decoder(4096)\n",
    "model = SingleModel(encoder, decoder)\n",
    "params = model.parameters()\n",
    "\n",
    "print(\"Total Params:\", count_params(model))\n",
    "\n",
    "# run on GPU\n",
    "use_cuda = False\n",
    "  \n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(params, lr=0.0004)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "\n",
    "try:\n",
    "  model.load_state_dict(torch.load(\"model_2.pt\"))\n",
    "  print(\"Model loaded\")\n",
    "except:\n",
    "  print(\"Error loading model\")\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2705
    },
    "colab_type": "code",
    "id": "OE9n2fEeVNBf",
    "outputId": "758e5024-82f2-4ff9-d3aa-12eda05884d7"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, print_metrics=0, num_epochs=3, display_images=1, scheduler=scheduler, save_path=\"model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4854
    },
    "colab_type": "code",
    "id": "mXnwpe6fX7gl",
    "outputId": "7bb7e3ef-4140-4a7c-a199-0516eb090dd8"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, print_metrics=0, num_epochs=5, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4854
    },
    "colab_type": "code",
    "id": "tSz0IKe0CdJF",
    "outputId": "b9774ca2-6c92-49b2-cc82-1735817731d0"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, print_metrics=0, num_epochs=5, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3304
    },
    "colab_type": "code",
    "id": "mcBLKvvgv9GU",
    "outputId": "7eab07fd-e6f4-4022-9b23-6e6ba4bff9af"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, print_metrics=0, num_epochs=5, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2944
    },
    "colab_type": "code",
    "id": "ghUmlY9S4NuZ",
    "outputId": "e4d969a7-aa44-4b26-9c8f-3060d4f7d9f0"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, print_metrics=0, num_epochs=5, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2963
    },
    "colab_type": "code",
    "id": "MpDJCGL8xzt1",
    "outputId": "c5b188f8-703a-4ec9-cf0d-aa70257b6d91"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, print_metrics=0, num_epochs=5, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3304
    },
    "colab_type": "code",
    "id": "3opXa99HKz61",
    "outputId": "c65c2230-dadc-4d07-f693-02838e43ad87"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, print_metrics=0, num_epochs=5, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1474
    },
    "colab_type": "code",
    "id": "mOaS_NobtxG1",
    "outputId": "075bbf96-e170-4250-cb3c-0acab06bbda0"
   },
   "outputs": [],
   "source": [
    "  train(model, train_loader, optimizer, print_metrics=0, num_epochs=5, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3304
    },
    "colab_type": "code",
    "id": "CBXnsSWtIhx5",
    "outputId": "e2701a17-742f-451b-f75f-f340c486d883"
   },
   "outputs": [],
   "source": [
    "  train(model, train_loader, optimizer, print_metrics=0, num_epochs=5, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2158
    },
    "colab_type": "code",
    "id": "Ne6X_hxSj3Ov",
    "outputId": "5a7df62e-bb89-4a08-dd84-7a223422f77e"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, optimizer, print_metrics=0, num_epochs=2, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "colab_type": "code",
    "id": "LUo20K5lORmy",
    "outputId": "2b80fc2b-6d98-421e-cee4-3e2449f7248c"
   },
   "outputs": [],
   "source": [
    "  train(model, train_loader, optimizer, print_metrics=0, num_epochs=8, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "colab_type": "code",
    "id": "f5Diyz9veyVO",
    "outputId": "c2a9d20e-1073-4044-9090-2a03cd18c763"
   },
   "outputs": [],
   "source": [
    "  train(model, train_loader, optimizer, print_metrics=0, num_epochs=5, display_images=1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "zEKvu8LEL-Fn",
    "outputId": "b50b16ef-90d8-4efa-ce69-8abfbde963f7"
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(loc=0.3, scale=7.5, size=4096).reshape((1,4096,1,1))\n",
    "image = model.decoder(torch.from_numpy(noise).cuda().float())\n",
    "plt.imshow(image[0].cpu().detach().permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VpXOVxeCTRTS"
   },
   "outputs": [],
   "source": [
    "# # download and unzip the data\n",
    "# url = \"https://s3.eu-west-3.amazonaws.com/deep.skoo.ch/GWB_64x64.zip\"\n",
    "# if not os.path.exists(\"gwb_images.zip\"):\n",
    "#   wget.download(url, 'gwb_images.zip')\n",
    "\n",
    "#   zip_ref = zipfile.ZipFile('gwb_images.zip', 'r')\n",
    "#   zip_ref.extractall('data/gwb')\n",
    "#   zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "upOOO2RqO5iG"
   },
   "outputs": [],
   "source": [
    "# use the existing encoder to create a GWBush decoder\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "  ## YOUR CODE HERE ##\n",
    "encoder = model.encoder\n",
    "gwb_decoder = Decoder(2048)\n",
    "gwb_model = SingleModel(encoder, gwb_decoder)\n",
    "gwb_params = gwb_model.decoder.parameters()\n",
    "\n",
    "# run on GPU\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    encoder.cuda()\n",
    "    gwb_decoder.cuda()\n",
    "    gwb_model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(gwb_params, lr=0.002)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HKfyJlqSPSj3"
   },
   "outputs": [],
   "source": [
    "# gwb dataset\n",
    "BATCH_SIZE = 64\n",
    "data_path = \"data/gwb\"\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.RandomHorizontalFlip(p=0.5), \n",
    "      torchvision.transforms.RandomChoice([\n",
    "        torchvision.transforms.RandomAffine(degrees=7, translate=(0.05,0.05), scale=(0.9,1.1), shear=3, resample=False, fillcolor=0),\n",
    "        torchvision.transforms.RandomResizedCrop((192,160), scale=(0.90, 1.1)),\n",
    "      ]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "gwb_train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "gwb_train_loader2 = torch.utils.data.DataLoader(\n",
    "    gwb_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "cheECT9oUNvk",
    "outputId": "5e83383e-faca-44d6-f5e6-600eafc0d043"
   },
   "outputs": [],
   "source": [
    "for (images, _) in gwb_train_loader2:\n",
    "  plt.imshow(images[0].permute(1,2,0))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5637
    },
    "colab_type": "code",
    "id": "XS_XIGPaPZm1",
    "outputId": "16c061b8-6d07-4dc4-8a1b-de415f508a94"
   },
   "outputs": [],
   "source": [
    "train(gwb_model, gwb_train_loader2, optimizer, print_metrics=0, num_epochs=200, display_images=20, scheduler=scheduler, save_path=\"./gwb_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "tJQ_deIUSca8",
    "sXm4SII5tR4t"
   ],
   "name": "eas7_HW9_faces.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
